{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7FFVANQhPYe"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/rmdluo/TartanHacks2023.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8mEBSkQKXrs"
      },
      "outputs": [],
      "source": [
        "!unzip TartanHacks2023/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA9d_gLMgwdl"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffdmh20bg1D4"
      },
      "outputs": [],
      "source": [
        "#data loading\n",
        "shape = (224, 224)\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\"garbage_classification\", image_size=shape, validation_split=0.2,\n",
        "  subset=\"training\", seed=123)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\"garbage_classification\", image_size=shape, validation_split=0.2,\n",
        "  subset=\"validation\", seed=123)\n",
        "\n",
        "classes = train_ds.class_names\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUA2YrHShX6y"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential, layers\n",
        "\n",
        "data_augmentation = Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=shape+(3,)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")\n",
        "\n",
        "base_model = keras.applications.Xception(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=shape+(3,),\n",
        "    include_top=False)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=shape+(3,))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)(x)\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "outputs = keras.layers.Dense(12)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2XxOkcvlQU_"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(patience = 2, verbose = 1, monitor='val_accuracy' , mode='max', min_delta=0.001, restore_best_weights = True)\n",
        "callbacks = [early_stop]\n",
        "\n",
        "hist = model.fit(\n",
        "    train_ds,\n",
        "    epochs=20,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JfZn5ai_4eM"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7GLqeTaIW7T"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "hist = model.fit(train_ds, epochs=epochs, validation_data=val_ds).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_6E9Hytm1jU"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAvAU-hWty2x"
      },
      "outputs": [],
      "source": [
        "# test the model\n",
        "img = cv2.imread(\"garbage_classification/battery/battery44.jpg\")\n",
        "img = cv2.resize(img, shape)\n",
        "prediction = model.predict(np.expand_dims(img, axis=0))\n",
        "print(classes[np.argmax(prediction)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xP7WXSMmmY3"
      },
      "outputs": [],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvgki4YpvVkm"
      },
      "outputs": [],
      "source": [
        "# load back in model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model_75.tflite\")\n",
        "classify_lite = interpreter.get_signature_runner('serving_default')\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# check the type of the input tensor\n",
        "floating_model = input_details[0]['dtype'] == np.float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXoo2bBmw4bS"
      },
      "outputs": [],
      "source": [
        "# test the lite model\n",
        "img = cv2.imread(\"garbage_classification/biological/biological124.jpg\")\n",
        "img = cv2.resize(img, shape)\n",
        "\n",
        "predictions_lite = classify_lite(input_2=np.float32(np.expand_dims(img, 0)))['dense']\n",
        "score_lite = tf.nn.softmax(predictions_lite)\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(classes[np.argmax(score_lite)], 100 * np.max(score_lite))\n",
        ")\n",
        "\n",
        "predictions = model.predict(np.float32(np.expand_dims(img, 0)))\n",
        "score = tf.nn.softmax(predictions)\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(classes[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpfoAG77xy6T"
      },
      "outputs": [],
      "source": [
        "# save the classes\n",
        "label_f = open(\"classes.txt\", mode=\"w\")\n",
        "\n",
        "for c in classes:\n",
        "  label_f.write(c+\"\\n\")\n",
        "\n",
        "label_f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsqm9tEkvSpR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.tflite\")\n",
        "files.download(\"classes.txt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7 (default, Nov 21 2021, 22:02:56)  [GCC 11.2.0 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "2a8dfe095fce2b5e88c64a2c3ee084c8e0e0d70b23e7b95b1cfb538be294c5c8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
